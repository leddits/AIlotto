{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOKr9lUCzMbh"
      },
      "source": [
        "## Get the TensorRT tar file before running this Notebook\n",
        "\n",
        "1. Visit https://developer.nvidia.com/tensorrt\n",
        "2. Clicking `Download now` from step one directs you to https://developer.nvidia.com/nvidia-tensorrt-download where you have to Login/Join Now for Nvidia Developer Program Membership\n",
        "3. Now, in the download page: Choose TensorRT 8 in available versions\n",
        "4. Agree to Terms and Conditions\n",
        "5. Click on TensorRT 8.6 GA to expand the available options\n",
        "6. Click on 'TensorRT 8.6 GA for Linux x86_64 and CUDA 12.0 and 12.1 TAR Package' to dowload the TAR file\n",
        "7. Upload the the tar file to your Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGLBrzF8hKgS"
      },
      "source": [
        "## Connect to GPU Instance\n",
        "\n",
        "1. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n",
        "1. Then click on Connect (Top Right)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjpjyNg5c2V9"
      },
      "source": [
        "## Mounting Google drive\n",
        "Mount your Google drive storage to this Colab instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvUVkYw0hzqG",
        "outputId": "543a926b-c358-4aee-bf34-8bb1406e7aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_COLAB=1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    %env GOOGLE_COLAB=1\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "else:\n",
        "    %env GOOGLE_COLAB=0\n",
        "    print(\"Warning: Not a Colab Environment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IZtVf3cPyom"
      },
      "source": [
        "# License Plate Recognition using TAO LPRNet\n",
        "\n",
        "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task.\n",
        "\n",
        "Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
        "\n",
        "<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png\" width=\"1080\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxZQEfTBPyoq"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n",
        "\n",
        "* Take a pretrained baseline18 LPRNet model and train it on the OpenALPR benchmark dataset\n",
        "* Run Inference on the trained model\n",
        "* Export the trained model to a .etlt file for deployment to DeepStream\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook shows an example usecase of LPRNet using Train Adapt Optimize (TAO) Toolkit.\n",
        "\n",
        "0. [Set up env variables](#head-0)\n",
        "1. [Prepare dataset and pre-trained model](#head-1) <br>\n",
        "    1.1 [Download pre-trained model](#head-1-1) <br>\n",
        "2. [Setup GPU environment](#head-2) <br>\n",
        "    2.1 [Setup Python environment](#head-2-1) <br>\n",
        "3. [Provide training specification](#head-3)\n",
        "4. [Run TAO training](#head-4)\n",
        "5. [Evaluate trained models](#head-5)\n",
        "6. [Inferences](#head-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5lxlv5IPyoq"
      },
      "source": [
        "#### Note\n",
        "1. This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly\n",
        "2. This notebook uses OPENALPR dataset by default, which should be around ~2.2 MB.\n",
        "3. Using the default config/spec file provided in this notebook, each weight file size of lprnet created during training will be ~111 MB\n",
        "\n",
        "## 0. Set up env variables and set FIXME parameters <a class=\"anchor\" id=\"head-0\"></a>\n",
        "\n",
        "*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly*\n",
        "\n",
        "#### FIXME\n",
        "1. NUM_GPUS - set this to <= number of GPU's availble on the instance\n",
        "1. GPU_INDEX - set to to the indices of the GPU available on the instance\n",
        "1. COLAB_NOTEBOOKS_PATH - for Google Colab environment, set this path where you want to clone the repo to; for local system environment, set this path to the already cloned repo\n",
        "1. EXPERIMENT_DIR - set this path to a folder location where pretrained models, checkpoints and log files during different model actions will be saved\n",
        "1. delete_existing_experiments - set to True to remove existing pretrained models, checkpoints and log files of a previous experiment\n",
        "1. DATA_DIR - set this path to a folder location where you want to dataset to be present\n",
        "1. delete_existing_data - set this to True to remove existing preprocessed and original data\n",
        "1. trt_tar_path - set this path of the uploaded TensorRT tar.gz file after browser download\n",
        "1. trt_untar_folder_path - set to path of the folder where the TensoRT tar.gz file has to be untarred into\n",
        "1. trt_version - set this to the version of TRT you have downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dXT1Uv__Pyor",
        "outputId": "9455a8b2-5d14-46ba-dfdb-dc31cdd92ff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TAO_DOCKER_DISABLE=1\n",
            "env: KEY=nvidia_tlt\n",
            "env: NUM_GPUS=1\n",
            "env: GPU_INDEX=0\n",
            "env: COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/nvidia-tao\n",
            "Cloning into '/content/drive/MyDrive/nvidia-tao'...\n",
            "remote: Enumerating objects: 2657, done.\u001b[K\n",
            "remote: Counting objects: 100% (350/350), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 2657 (delta 241), reused 251 (delta 157), pack-reused 2307 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2657/2657), 4.05 MiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (1735/1735), done.\n",
            "env: EXPERIMENT_DIR=/content/drive/MyDrive/results/lprnet\n",
            "env: DATA_DIR=/content/drive/MyDrive/lprnet_data/\n",
            "env: SPECS_DIR=/content/drive/MyDrive/nvidia-tao/tensorflow/lprnet/specs\n",
            "total 2\n",
            "-rw------- 1 root root   70 Apr 10 22:24 us_lp_characters.txt\n",
            "-rw------- 1 root root 1137 Apr 10 22:24 tutorial_spec.txt\n"
          ]
        }
      ],
      "source": [
        "# Setting up env variables for cleaner command line commands.\n",
        "import os\n",
        "\n",
        "%env TAO_DOCKER_DISABLE=1\n",
        "\n",
        "%env KEY=nvidia_tlt\n",
        "#FIXME1\n",
        "%env NUM_GPUS=1\n",
        "#FIXME2\n",
        "%env GPU_INDEX=0\n",
        "\n",
        "#FIXME3\n",
        "%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/nvidia-tao\n",
        "if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n",
        "    if not os.path.exists(os.path.join(os.environ[\"COLAB_NOTEBOOKS_PATH\"])):\n",
        "\n",
        "      !git clone https://github.com/NVIDIA-AI-IOT/nvidia-tao.git $COLAB_NOTEBOOKS_PATH\n",
        "else:\n",
        "    if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n",
        "        raise Exception(\"Error, enter the path of the colab notebooks repo correctly\")\n",
        "\n",
        "#FIXME4\n",
        "%env EXPERIMENT_DIR=/content/drive/MyDrive/results/lprnet\n",
        "#FIXME5\n",
        "delete_existing_experiments = True\n",
        "#FIXME6\n",
        "%env DATA_DIR=/content/drive/MyDrive/lprnet_data/\n",
        "#FIXME7\n",
        "delete_existing_data = False\n",
        "\n",
        "if delete_existing_experiments:\n",
        "    !sudo rm -rf $EXPERIMENT_DIR\n",
        "if delete_existing_data:\n",
        "    !sudo rm -rf $DATA_DIR\n",
        "\n",
        "SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/lprnet/specs\"\n",
        "%env SPECS_DIR={SPECS_DIR}\n",
        "# Showing list of specification files.\n",
        "!ls -rlt $SPECS_DIR\n",
        "\n",
        "!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n",
        "!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI_8N9_IPyov"
      },
      "source": [
        "## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvQbbU5wPyov"
      },
      "source": [
        " We will be using the OpenALPR benchmark dataset for the tutorial. The following script will download the dataset automatically and convert it to the format used by TAO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kBI24bHSPyov",
        "outputId": "6bf33476-d13c-4bd9-f873-83161678ef0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ '[' -z /content/drive/MyDrive/lprnet_data/ ']'\n",
            "++ pwd\n",
            "+ CURRENT_DIR=/content\n",
            "+ echo 'Cloning OpenALPR benchmark directory'\n",
            "Cloning OpenALPR benchmark directory\n",
            "+ '[' '!' -e benchmarks ']'\n",
            "+ git clone https://github.com/openalpr/benchmarks benchmarks\n",
            "Cloning into 'benchmarks'...\n",
            "remote: Enumerating objects: 1752, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 1752 (delta 22), reused 22 (delta 22), pack-reused 1728 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1752/1752), 187.98 MiB | 44.89 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "+ OUTPUT_DIR=/content/drive/MyDrive/lprnet_data\n",
            "+ mkdir -p /content/drive/MyDrive/lprnet_data\n",
            "+++ readlink -f /content/drive/MyDrive/nvidia-tao/tensorflow/lprnet/download_and_prepare_data.sh\n",
            "++ dirname /content/drive/MyDrive/nvidia-tao/tensorflow/lprnet/download_and_prepare_data.sh\n",
            "+ SCRIPT_DIR=/content/drive/MyDrive/nvidia-tao/tensorflow/lprnet\n",
            "+ echo 'Preprocessing OpenALPR benchmarks data for US'\n",
            "Preprocessing OpenALPR benchmarks data for US\n",
            "+ python3 /content/drive/MyDrive/nvidia-tao/tensorflow/lprnet/preprocess_openalpr_benchmark.py --input_dir=/content/benchmarks/endtoend/us/ --output_dir=/content/drive/MyDrive/lprnet_data\n",
            "Total 222 samples in benchmark dataset\n",
            "111 for train and 111 for val\n"
          ]
        }
      ],
      "source": [
        "!bash $COLAB_NOTEBOOKS_PATH/tensorflow/lprnet/download_and_prepare_data.sh $DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Oi9ACFA0Pyov",
        "outputId": "dd1a1096-ee01-432c-8eb4-6deb8b07aafa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lprnet_data/\n",
            "total 8\n",
            "drwx------ 4 root root 4096 Apr 10 22:41 train\n",
            "drwx------ 4 root root 4096 Apr 10 22:41 val\n",
            "total 8\n",
            "drwx------ 2 root root 4096 Apr 10 22:41 image\n",
            "drwx------ 2 root root 4096 Apr 10 22:41 label\n",
            "total 504\n",
            "-rw------- 1 root root 10710 Apr 10 22:41 316b64c0-55bf-4079-a1c0-d93f461a576f.jpg\n",
            "-rw------- 1 root root  2003 Apr 10 22:41 33fa5185-0286-4e8f-b775-46162eba39d4.jpg\n",
            "-rw------- 1 root root  2092 Apr 10 22:41 37170dd1-2802-4e38-b982-c5d07c64ff67.jpg\n",
            "-rw------- 1 root root  2067 Apr 10 22:41 4be2025c-09f7-4bb0-b1bd-8e8633e6dec1.jpg\n",
            "-rw------- 1 root root  2286 Apr 10 22:41 7fbfbe28-aecb-45be-bd05-7cf26acb3c5c.jpg\n",
            "-rw------- 1 root root  8449 Apr 10 22:41 car12.jpg\n",
            "-rw------- 1 root root  3431 Apr 10 22:41 car14.jpg\n",
            "-rw------- 1 root root  4161 Apr 10 22:41 car15.jpg\n",
            "-rw------- 1 root root  2911 Apr 10 22:41 car16.jpg\n",
            "-rw------- 1 root root  1748 Apr 10 22:41 car17.jpg\n",
            "-rw------- 1 root root  2387 Apr 10 22:41 car18.jpg\n",
            "-rw------- 1 root root  5296 Apr 10 22:41 car1.jpg\n",
            "-rw------- 1 root root  1650 Apr 10 22:41 car22.jpg\n",
            "-rw------- 1 root root  3355 Apr 10 22:41 car2.jpg\n",
            "-rw------- 1 root root  2748 Apr 10 22:41 car6.jpg\n",
            "-rw------- 1 root root 11377 Apr 10 22:41 car7.jpg\n",
            "-rw------- 1 root root  6907 Apr 10 22:41 car9-0.jpg\n",
            "-rw------- 1 root root 11997 Apr 10 22:41 car9-1.jpg\n",
            "-rw------- 1 root root  4836 Apr 10 22:41 car9-4.jpg\n",
            "-rw------- 1 root root  6960 Apr 10 22:41 car9-5.jpg\n",
            "-rw------- 1 root root  6260 Apr 10 22:41 car9-7.jpg\n",
            "-rw------- 1 root root  3626 Apr 10 22:41 car9-9.jpg\n",
            "-rw------- 1 root root  3125 Apr 10 22:41 car9.jpg\n",
            "-rw------- 1 root root  1974 Apr 10 22:41 cfaa9dd2-a388-4e92-bb3a-ae65c28d8139.jpg\n",
            "-rw------- 1 root root  2112 Apr 10 22:41 d4f79480-366a-40b6-ab2c-328bcba705b2.jpg\n",
            "-rw------- 1 root root  1918 Apr 10 22:41 f8fc5e59-9083-466b-ae3f-6b869a0b257b.jpg\n",
            "-rw------- 1 root root  5125 Apr 10 22:41 us1.jpg\n",
            "-rw------- 1 root root  4186 Apr 10 22:41 us3.jpg\n",
            "-rw------- 1 root root  9130 Apr 10 22:41 us4.jpg\n",
            "-rw------- 1 root root 13834 Apr 10 22:41 us5.jpg\n",
            "-rw------- 1 root root 38963 Apr 10 22:41 us8.jpg\n",
            "-rw------- 1 root root  4466 Apr 10 22:41 wts-lg-000011.jpg\n",
            "-rw------- 1 root root  2402 Apr 10 22:41 wts-lg-000012.jpg\n",
            "-rw------- 1 root root  2169 Apr 10 22:41 wts-lg-000014.jpg\n",
            "-rw------- 1 root root  3763 Apr 10 22:41 wts-lg-000017.jpg\n",
            "-rw------- 1 root root  1703 Apr 10 22:41 wts-lg-000018.jpg\n",
            "-rw------- 1 root root  5038 Apr 10 22:41 wts-lg-000020.jpg\n",
            "-rw------- 1 root root  2397 Apr 10 22:41 wts-lg-000022.jpg\n",
            "-rw------- 1 root root  4342 Apr 10 22:41 wts-lg-000024.jpg\n",
            "-rw------- 1 root root  4065 Apr 10 22:41 wts-lg-000026.jpg\n",
            "-rw------- 1 root root  6964 Apr 10 22:41 wts-lg-000027.jpg\n",
            "-rw------- 1 root root  1882 Apr 10 22:41 wts-lg-000036.jpg\n",
            "-rw------- 1 root root  2849 Apr 10 22:41 wts-lg-000038.jpg\n",
            "-rw------- 1 root root  2160 Apr 10 22:41 wts-lg-000039.jpg\n",
            "-rw------- 1 root root  3745 Apr 10 22:41 wts-lg-000040.jpg\n",
            "-rw------- 1 root root  2448 Apr 10 22:41 wts-lg-000045.jpg\n",
            "-rw------- 1 root root  2045 Apr 10 22:41 wts-lg-000046.jpg\n",
            "-rw------- 1 root root  2309 Apr 10 22:41 wts-lg-000050.jpg\n",
            "-rw------- 1 root root  4337 Apr 10 22:41 wts-lg-000051.jpg\n",
            "-rw------- 1 root root  2773 Apr 10 22:41 wts-lg-000052.jpg\n",
            "-rw------- 1 root root  2040 Apr 10 22:41 wts-lg-000053.jpg\n",
            "-rw------- 1 root root  1929 Apr 10 22:41 wts-lg-000055.jpg\n",
            "-rw------- 1 root root  3038 Apr 10 22:41 wts-lg-000056.jpg\n",
            "-rw------- 1 root root  3535 Apr 10 22:41 wts-lg-000060.jpg\n",
            "-rw------- 1 root root  4655 Apr 10 22:41 wts-lg-000065.jpg\n",
            "-rw------- 1 root root  2069 Apr 10 22:41 wts-lg-000067.jpg\n",
            "-rw------- 1 root root  1710 Apr 10 22:41 wts-lg-000068.jpg\n",
            "-rw------- 1 root root  4094 Apr 10 22:41 wts-lg-000070.jpg\n",
            "-rw------- 1 root root  2084 Apr 10 22:41 wts-lg-000072.jpg\n",
            "-rw------- 1 root root  3319 Apr 10 22:41 wts-lg-000073.jpg\n",
            "-rw------- 1 root root  4047 Apr 10 22:41 wts-lg-000074.jpg\n",
            "-rw------- 1 root root  5239 Apr 10 22:41 wts-lg-000077.jpg\n",
            "-rw------- 1 root root  3268 Apr 10 22:41 wts-lg-000078.jpg\n",
            "-rw------- 1 root root  3542 Apr 10 22:41 wts-lg-000084.jpg\n",
            "-rw------- 1 root root  1887 Apr 10 22:41 wts-lg-000088.jpg\n",
            "-rw------- 1 root root  1821 Apr 10 22:41 wts-lg-000089.jpg\n",
            "-rw------- 1 root root  3370 Apr 10 22:41 wts-lg-000090.jpg\n",
            "-rw------- 1 root root  2953 Apr 10 22:41 wts-lg-000096.jpg\n",
            "-rw------- 1 root root  3838 Apr 10 22:41 wts-lg-000098.jpg\n",
            "-rw------- 1 root root  3725 Apr 10 22:41 wts-lg-000099.jpg\n",
            "-rw------- 1 root root  3232 Apr 10 22:41 wts-lg-000100.jpg\n",
            "-rw------- 1 root root  3084 Apr 10 22:41 wts-lg-000101.jpg\n",
            "-rw------- 1 root root  2304 Apr 10 22:41 wts-lg-000113.jpg\n",
            "-rw------- 1 root root  3837 Apr 10 22:41 wts-lg-000117.jpg\n",
            "-rw------- 1 root root  2286 Apr 10 22:41 wts-lg-000121.jpg\n",
            "-rw------- 1 root root  2512 Apr 10 22:41 wts-lg-000124.jpg\n",
            "-rw------- 1 root root  2778 Apr 10 22:41 wts-lg-000125.jpg\n",
            "-rw------- 1 root root  2357 Apr 10 22:41 wts-lg-000126.jpg\n",
            "-rw------- 1 root root  3239 Apr 10 22:41 wts-lg-000127.jpg\n",
            "-rw------- 1 root root  6309 Apr 10 22:41 wts-lg-000129.jpg\n",
            "-rw------- 1 root root  3119 Apr 10 22:41 wts-lg-000131.jpg\n",
            "-rw------- 1 root root  6167 Apr 10 22:41 wts-lg-000135.jpg\n",
            "-rw------- 1 root root  7349 Apr 10 22:41 wts-lg-000137.jpg\n",
            "-rw------- 1 root root  5291 Apr 10 22:41 wts-lg-000138.jpg\n",
            "-rw------- 1 root root  2802 Apr 10 22:41 wts-lg-000139.jpg\n",
            "-rw------- 1 root root  2880 Apr 10 22:41 wts-lg-000141.jpg\n",
            "-rw------- 1 root root  4114 Apr 10 22:41 wts-lg-000143.jpg\n",
            "-rw------- 1 root root  3751 Apr 10 22:41 wts-lg-000149.jpg\n",
            "-rw------- 1 root root  6083 Apr 10 22:41 wts-lg-000155.jpg\n",
            "-rw------- 1 root root  2580 Apr 10 22:41 wts-lg-000156.jpg\n",
            "-rw------- 1 root root  4291 Apr 10 22:41 wts-lg-000157.jpg\n",
            "-rw------- 1 root root  7101 Apr 10 22:41 wts-lg-000162.jpg\n",
            "-rw------- 1 root root  4186 Apr 10 22:41 wts-lg-000163.jpg\n",
            "-rw------- 1 root root  7106 Apr 10 22:41 wts-lg-000165.jpg\n",
            "-rw------- 1 root root  3097 Apr 10 22:41 wts-lg-000166.jpg\n",
            "-rw------- 1 root root  8129 Apr 10 22:41 wts-lg-000168.jpg\n",
            "-rw------- 1 root root  4709 Apr 10 22:41 wts-lg-000169.jpg\n",
            "-rw------- 1 root root  3655 Apr 10 22:41 wts-lg-000172.jpg\n",
            "-rw------- 1 root root  4448 Apr 10 22:41 wts-lg-000174.jpg\n",
            "-rw------- 1 root root  8097 Apr 10 22:41 wts-lg-000176.jpg\n",
            "-rw------- 1 root root  4624 Apr 10 22:41 wts-lg-000177.jpg\n",
            "-rw------- 1 root root  3419 Apr 10 22:41 wts-lg-000178.jpg\n",
            "-rw------- 1 root root  1933 Apr 10 22:41 wts-lg-000183.jpg\n",
            "-rw------- 1 root root  3435 Apr 10 22:41 wts-lg-000186.jpg\n",
            "-rw------- 1 root root  2049 Apr 10 22:41 wts-lg-000189.jpg\n",
            "-rw------- 1 root root  4504 Apr 10 22:41 wts-lg-000190.jpg\n",
            "-rw------- 1 root root  3808 Apr 10 22:41 wts-lg-000192.jpg\n",
            "-rw------- 1 root root  6398 Apr 10 22:41 wts-lg-000193.jpg\n",
            "-rw------- 1 root root  3890 Apr 10 22:41 wts-lg-000195.jpg\n",
            "-rw------- 1 root root  6452 Apr 10 22:41 wts-lg-000196.jpg\n",
            "-rw------- 1 root root  2671 Apr 10 22:41 wts-lg-000197.jpg\n",
            "total 56\n",
            "-rw------- 1 root root 7 Apr 10 22:41 316b64c0-55bf-4079-a1c0-d93f461a576f.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 33fa5185-0286-4e8f-b775-46162eba39d4.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 37170dd1-2802-4e38-b982-c5d07c64ff67.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 4be2025c-09f7-4bb0-b1bd-8e8633e6dec1.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 7fbfbe28-aecb-45be-bd05-7cf26acb3c5c.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car12.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 car14.txt\n",
            "-rw------- 1 root root 5 Apr 10 22:41 car15.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 car16.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car17.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 car18.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 car1.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 car22.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car2.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car6.txt\n",
            "-rw------- 1 root root 5 Apr 10 22:41 car7.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 car9-0.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car9-1.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car9-4.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car9-5.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car9-7.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 car9-9.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 car9.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 cfaa9dd2-a388-4e92-bb3a-ae65c28d8139.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 d4f79480-366a-40b6-ab2c-328bcba705b2.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 f8fc5e59-9083-466b-ae3f-6b869a0b257b.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 us1.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 us3.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 us4.txt\n",
            "-rw------- 1 root root 8 Apr 10 22:41 us5.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 us8.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000011.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000012.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000014.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000017.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000018.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000020.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000022.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000024.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000026.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000027.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000036.txt\n",
            "-rw------- 1 root root 5 Apr 10 22:41 wts-lg-000038.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000039.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000040.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000045.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000046.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000050.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000051.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000052.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000053.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000055.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000056.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000060.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000065.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000067.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000068.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000070.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000072.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000073.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000074.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000077.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000078.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000084.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000088.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000089.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000090.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000096.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000098.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000099.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000100.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000101.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000113.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000117.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000121.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000124.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000125.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000126.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000127.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000129.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000131.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000135.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000137.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000138.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000139.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000141.txt\n",
            "-rw------- 1 root root 5 Apr 10 22:41 wts-lg-000143.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000149.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000155.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000156.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000157.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000162.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000163.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000165.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000166.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000168.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000169.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000172.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000174.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000176.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000177.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000178.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000183.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000186.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000189.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000190.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000192.txt\n",
            "-rw------- 1 root root 6 Apr 10 22:41 wts-lg-000193.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000195.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000196.txt\n",
            "-rw------- 1 root root 7 Apr 10 22:41 wts-lg-000197.txt\n"
          ]
        }
      ],
      "source": [
        "# verify\n",
        "!echo $DATA_DIR\n",
        "!ls -l $DATA_DIR/\n",
        "!ls -l $DATA_DIR/train\n",
        "!ls -l $DATA_DIR/train/image\n",
        "!ls -l $DATA_DIR/train/label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2B28ZwpPyox"
      },
      "source": [
        "### 1.1 Download pretrained model from NGC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU1c75iPPyox"
      },
      "source": [
        "We will use NGC CLI to get the pre-trained models. For more details, go to https://ngc.nvidia.com and click the SETUP on the navigation bar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "85pHGpdOPyoy",
        "outputId": "ea7c08b5-3952-4bd0-ccb1-be53c6d24b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LOCAL_PROJECT_DIR=/ngc_content/\n",
            "env: CLI=ngccli_cat_linux.zip\n",
            "--2025-04-10 22:41:34--  https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.23.0/files/ngccli_linux.zip\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 54.201.78.208, 35.162.242.49\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|54.201.78.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xfiles.ngc.nvidia.com/org/nvidia/team/ngc-apps/recipes/ngc_cli/versions/3.23.0/files/ngccli_linux.zip?Signature=mpxYr3swpl3h7vZTbOjq-8kd2eJoD1taEbClK6CKQHfxDOUKnRHPxMlL-s86nFIFb~o7ClzlNzsOOxmdc2Och4M2vdjpCyGDjgJQEl7lWiUJoOxlKyCSfm8ZvnEgdOLTbdcox-gws02CWYBHQG6CenjlMeOWaUQKx4ZGDjoH8105z9Wsi1m~b~2SnM~s8kPpFZmXfuoBbZVrCrMnrKqfSo7iLSXKBGONo37NtdOl2JInC8KNZ5DyH5~hWXk2FsUQ-jaQygunD6mAjWN5RwjFT7dcKd21Jc5c9K954wlC0uaJf-22iGmF8rM6XwLsZ9amX-lMorj7-p81rlBpserJRA__&Expires=1744411295&Key-Pair-Id=KCX06E8E9L60W [following]\n",
            "--2025-04-10 22:41:35--  https://xfiles.ngc.nvidia.com/org/nvidia/team/ngc-apps/recipes/ngc_cli/versions/3.23.0/files/ngccli_linux.zip?Signature=mpxYr3swpl3h7vZTbOjq-8kd2eJoD1taEbClK6CKQHfxDOUKnRHPxMlL-s86nFIFb~o7ClzlNzsOOxmdc2Och4M2vdjpCyGDjgJQEl7lWiUJoOxlKyCSfm8ZvnEgdOLTbdcox-gws02CWYBHQG6CenjlMeOWaUQKx4ZGDjoH8105z9Wsi1m~b~2SnM~s8kPpFZmXfuoBbZVrCrMnrKqfSo7iLSXKBGONo37NtdOl2JInC8KNZ5DyH5~hWXk2FsUQ-jaQygunD6mAjWN5RwjFT7dcKd21Jc5c9K954wlC0uaJf-22iGmF8rM6XwLsZ9amX-lMorj7-p81rlBpserJRA__&Expires=1744411295&Key-Pair-Id=KCX06E8E9L60W\n",
            "Resolving xfiles.ngc.nvidia.com (xfiles.ngc.nvidia.com)... 18.239.50.3, 18.239.50.107, 18.239.50.128, ...\n",
            "Connecting to xfiles.ngc.nvidia.com (xfiles.ngc.nvidia.com)|18.239.50.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43271011 (41M) [binary/octet-stream]\n",
            "Saving to: ‘/ngc_content//ngccli/ngccli_cat_linux.zip’\n",
            "\n",
            "ngccli_cat_linux.zi 100%[===================>]  41.27M  16.9MB/s    in 2.4s    \n",
            "\n",
            "2025-04-10 22:41:38 (16.9 MB/s) - ‘/ngc_content//ngccli/ngccli_cat_linux.zip’ saved [43271011/43271011]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Installing NGC CLI on the local machine.\n",
        "## Download and install\n",
        "%env LOCAL_PROJECT_DIR=/ngc_content/\n",
        "%env CLI=ngccli_cat_linux.zip\n",
        "!sudo mkdir -p $LOCAL_PROJECT_DIR/ngccli && sudo chmod -R 777 $LOCAL_PROJECT_DIR\n",
        "\n",
        "# Remove any previously existing CLI installations\n",
        "!sudo rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n",
        "!wget --content-disposition 'https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.23.0/files/ngccli_linux.zip' -P $LOCAL_PROJECT_DIR/ngccli -O $LOCAL_PROJECT_DIR/ngccli/$CLI\n",
        "!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n",
        "!rm $LOCAL_PROJECT_DIR/ngccli/*.zip\n",
        "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n",
        "!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IcsQ_FWqPyoy",
        "outputId": "8c9e732a-6bfb-40d2-e234-195255f4deed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+----------+--------+------------+-----------+------------------+-----------+-----------------+--------------+\n",
            "| Version              | Accuracy | Epochs | Batch Size | GPU Model | Memory Footprint | File Size | Status          | Created Date |\n",
            "+----------------------+----------+--------+------------+-----------+------------------+-----------+-----------------+--------------+\n",
            "| trainable_v1.0       | 99.67    | 120    | 1          | V100      | 221.1            | 221.06 MB | UPLOAD_COMPLETE | Aug 24, 2021 |\n",
            "| deployable_v1.0      | 99.67    | 120    | 1          | V100      | 110.1            | 110.09 MB | UPLOAD_COMPLETE | Aug 24, 2021 |\n",
            "| deployable_onnx_v1.1 |          |        |            |           |                  | 110.09 MB | UPLOAD_COMPLETE | Sep 20, 2024 |\n",
            "+----------------------+----------+--------+------------+-----------+------------------+-----------+-----------------+--------------+\n"
          ]
        }
      ],
      "source": [
        "# @title 기본 제목 텍스트\n",
        "!ngc registry model list nvidia/tao/lprnet:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dAx-bsIDPyoy"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/pretrained_lprnet_baseline18/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8EieO4uYPyoy",
        "outputId": "7b337073-f295-4bce-a23d-38d369bcfdd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting files to download...\n",
            "\u001b[?25l\u001b[32m⠋\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠇\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠏\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m0…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m…\u001b[0m • \u001b[31m?\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 0 - Failed: 0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m \u001b[36m━━\u001b[0m • \u001b[32m…\u001b[0m • \u001b[36mRemaining:\u001b[0m \u001b[36m3…\u001b[0m • \u001b[31m…\u001b[0m • \u001b[33mElapsed:\u001b[0m \u001b[33m0…\u001b[0m • \u001b[34mTotal: 4 - Completed: 4 - Failed: 0\u001b[0m\n",
            "       \u001b[32m…\u001b[0m                   \u001b[31m…\u001b[0m                                                    \n",
            "\u001b[?25h\n",
            "--------------------------------------------------------------------------------\n",
            "   Download status: COMPLETED\n",
            "   Downloaded local path model: /content/drive/MyDrive/results/lprnet/pretrained_lprnet_baseline18/lprnet_vtrainable_v1.0\n",
            "   Total files downloaded: 4\n",
            "   Total transferred: 440 B\n",
            "   Started at: 2025-04-10 22:43:27\n",
            "   Completed at: 2025-04-10 22:43:28\n",
            "   Duration taken: 0s\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Pull pretrained model from NGC\n",
        "!ngc registry model download-version nvidia/tao/lprnet:trainable_v1.0 --dest $EXPERIMENT_DIR/pretrained_lprnet_baseline18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m0ANlm3XPyoz",
        "outputId": "94b259c9-5672-4804-fdee-0b92cc93947a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check that model is downloaded into dir.\n",
            "total 2\n",
            "-rw------- 1 root root 110 Apr 10 22:43 ch_lp_characters.txt\n",
            "-rw------- 1 root root 110 Apr 10 22:43 ch_lprnet_baseline18_trainable.tlt\n",
            "-rw------- 1 root root 110 Apr 10 22:43 us_lp_characters.txt\n",
            "-rw------- 1 root root 110 Apr 10 22:43 us_lprnet_baseline18_trainable.tlt\n"
          ]
        }
      ],
      "source": [
        "print(\"Check that model is downloaded into dir.\")\n",
        "!ls -l $EXPERIMENT_DIR/pretrained_lprnet_baseline18/lprnet_vtrainable_v1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_26rCobXcri1"
      },
      "source": [
        "## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBV_YWiTc_KM"
      },
      "source": [
        "### 2.1 Setup Python environment <a class=\"anchor\" id=\"head-2-1\"></a>\n",
        "Setup the environment necessary to run the TAO Networks by running the bash script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "s2Xygw-y8fjm",
        "outputId": "ba715ccb-d48a-4bfe-c2ab-52db0720d591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "TAR file not found in the provided path",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3b045403728c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt_tar_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TAR file not found in the provided path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# FIXME 8: set to path of the folder where the TensoRT tar.gz file has to be untarred into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: TAR file not found in the provided path"
          ]
        }
      ],
      "source": [
        "# FIXME 7: set this path of the uploaded TensorRT tar.gz file after browser download\n",
        "trt_tar_path=\"/content/drive/MyDrive/nvidia-tao/TensorRT-10.9.0.34.Linux.x86_64-gnu.cuda-11.8.tar.gz\"\n",
        "\n",
        "import os\n",
        "if not os.path.exists(trt_tar_path):\n",
        "  raise Exception(\"TAR file not found in the provided path\")\n",
        "\n",
        "# FIXME 8: set to path of the folder where the TensoRT tar.gz file has to be untarred into\n",
        "%env trt_untar_folder_path=/content/trt_untar\n",
        "# FIXME 9: set this to the version of TRT you have downloaded\n",
        "%env trt_version=10.9.0.34\n",
        "\n",
        "!sudo mkdir -p $trt_untar_folder_path && sudo chmod -R 777 $trt_untar_folder_path/\n",
        "\n",
        "import os\n",
        "\n",
        "untar = True\n",
        "for fname in os.listdir(os.environ.get(\"trt_untar_folder_path\", None)):\n",
        "  if fname.startswith(\"TensorRT-\"+os.environ.get(\"trt_version\")) and not fname.endswith(\".tar.gz\"):\n",
        "    untar = False\n",
        "\n",
        "if untar:\n",
        "  !tar -xzf $trt_tar_path -C /content/trt_untar\n",
        "\n",
        "if os.environ.get(\"LD_LIBRARY_PATH\",\"\") == \"\":\n",
        "  os.environ[\"LD_LIBRARY_PATH\"] = \"\"\n",
        "trt_lib_path = f':{os.environ.get(\"trt_untar_folder_path\")}/TensorRT-{os.environ.get(\"trt_version\")}/lib'\n",
        "os.environ[\"LD_LIBRARY_PATH\"]+=trt_lib_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4-8C1OzzMbk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n",
        "    os.environ[\"bash_script\"] = \"setup_env.sh\"\n",
        "else:\n",
        "    os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n",
        "\n",
        "os.environ[\"NV_TAO_TF_TOP\"] = \"/tmp/tao_tensorflow1_backend/\"\n",
        "\n",
        "!sed -i \"s|PATH_TO_TRT|$trt_untar_folder_path|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n",
        "!sed -i \"s|TRT_VERSION|$trt_version|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n",
        "!sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n",
        "\n",
        "!sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N3YWk16Pyoz"
      },
      "source": [
        "## 3. Provide training specification <a class=\"anchor\" id=\"head-3\"></a>\n",
        "\n",
        "* Note the spec $SPEC_DIR/default_sepc.txt is for training on US license plates:\n",
        "    * the max license plate length is 8;\n",
        "        * You can change `max_label_length` in `lpr_config` to satisfy your own dataset.\n",
        "    * the characters of US license plates are: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F, G, H, I, J, K, L, M, N, P, Q, R, S, T, U, V, W, X, Y, Z\n",
        "        * You can change `characters_list_file` in `dataset_config` to set your own characters.\n",
        "        * `characters_list_file` should contain all the characters in dataset. And one character takes one line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3fLUuoaPyo0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/tutorial_spec.txt\n",
        "!sed -i \"s|TAO_SPEC_DIR|$SPECS_DIR/|g\" $SPECS_DIR/tutorial_spec.txt\n",
        "!cat $SPECS_DIR/tutorial_spec.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb9OAcd7Pyo0"
      },
      "outputs": [],
      "source": [
        "!cat $SPECS_DIR/us_lp_characters.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XifdFs5Pyo0"
      },
      "source": [
        "## 4. Run TAO training <a class=\"anchor\" id=\"head-4\"></a>\n",
        "* Provide the sample spec file and the output directory location for models\n",
        "* WARNING: training will take several hours or one day to complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnhmABuWPyo0"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/experiment_dir_unpruned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8wKuOHNPyo1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(\"For multi-GPU, change --gpus based on your machine.\")\n",
        "!tao model lprnet train --gpus=1 --gpu_index=$GPU_INDEX \\\n",
        "                  -e $SPECS_DIR/tutorial_spec.txt \\\n",
        "                  -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
        "                  -k $KEY \\\n",
        "                  -m $EXPERIMENT_DIR/pretrained_lprnet_baseline18/lprnet_vtrainable_v1.0/us_lprnet_baseline18_trainable.tlt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7I87ZIdPyo1"
      },
      "outputs": [],
      "source": [
        "print(\"To resume training from a checkpoint, set the -m option to be the .tlt you want to resume from and --initial_epochs to be the epoch index of the resumed checkpoint\")\n",
        "# !tao model lprnet train --gpu_index=$GPU_INDEX \\\n",
        "#                   -e $SPECS_DIR/tutorial_spec.txt \\\n",
        "#                   -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
        "#                   -k $KEY \\\n",
        "#                   -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/lprnet_epoch-01.tlt\n",
        "#                   --initial_epoch 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDkWKQQkPyo1"
      },
      "outputs": [],
      "source": [
        "print('Model for each epoch:')\n",
        "print('---------------------')\n",
        "!ls -ltrh $EXPERIMENT_DIR/experiment_dir_unpruned/weights/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCYg-llnPyo1"
      },
      "source": [
        "## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELV8uJr-Pyo2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!tao model lprnet evaluate --gpu_index=$GPU_INDEX -e $SPECS_DIR/tutorial_spec.txt \\\n",
        "                     -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/lprnet_epoch-024.hdf5 \\\n",
        "                     -k $KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvZE4H8KPyo2"
      },
      "source": [
        "## 6. Inferences <a class=\"anchor\" id=\"head-6\"></a>\n",
        "In this section, we run the lprnet inference tool to generate inferences on the trained models and print the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlqyTE7MPyo3"
      },
      "outputs": [],
      "source": [
        "# Running inference for detection on n images\n",
        "!tao model lprnet inference --gpu_index=$GPU_INDEX -i $DATA_DIR/val/image \\\n",
        "                      -e $SPECS_DIR/tutorial_spec.txt \\\n",
        "                      -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/lprnet_epoch-024.hdf5 \\\n",
        "                      -k $KEY"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lprnet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}